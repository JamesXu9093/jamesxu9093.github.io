<!DOCTYPE html>
<html lang="zh-Hans">
<head>

    <!--[if lt IE 9]>
        <style>body {display: none; background: none !important} </style>
        <meta http-equiv="Refresh" Content="0; url=//outdatedbrowser.com/" />
    <![endif]-->

<meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge, chrome=1" />
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1, user-scalable=no">
<meta name="format-detection" content="telephone=no" />
<meta name="author" content="James" />



<meta name="description" content="spark作为当下大数据领域最炙手可热的数据处理框架，版本的更新、迭代速度也是非常之快，由学习的时候1.3的版本，到1.4，到1.6，到现在的2.0版本。以下为本人学习过程以及需要努力的方向：1、spark原理：rdd(新的2.0版本rdd并不是推荐的数据表示形式，而是DataFram)2、spark-streaming3、spark-sql4、spark-mllib">
<meta property="og:type" content="article">
<meta property="og:title" content="Spark学习归纳总结">
<meta property="og:url" content="https://jamesxu9093.github.io/2016/12/15/spark学习归纳/index.html">
<meta property="og:site_name" content="James的博客">
<meta property="og:description" content="spark作为当下大数据领域最炙手可热的数据处理框架，版本的更新、迭代速度也是非常之快，由学习的时候1.3的版本，到1.4，到1.6，到现在的2.0版本。以下为本人学习过程以及需要努力的方向：1、spark原理：rdd(新的2.0版本rdd并不是推荐的数据表示形式，而是DataFram)2、spark-streaming3、spark-sql4、spark-mllib">
<meta property="og:image" content="https://jamesxu9093.github.io/blog-img/1219-1.png">
<meta property="og:image" content="https://jamesxu9093.github.io/blog-img/1219-2.png">
<meta property="og:image" content="https://jamesxu9093.github.io/blog-img/1219-3.png">
<meta property="og:image" content="https://jamesxu9093.github.io/blog-img/1219-4.png">
<meta property="og:image" content="https://jamesxu9093.github.io/blog-img/1219-5.png">
<meta property="og:image" content="https://jamesxu9093.github.io/blog-img/1219-6.png">
<meta property="og:image" content="https://jamesxu9093.github.io/blog-img/1219-7.png">
<meta property="og:image" content="https://jamesxu9093.github.io/blog-img/1219-8.png">
<meta property="og:updated_time" content="2016-12-19T07:14:06.563Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Spark学习归纳总结">
<meta name="twitter:description" content="spark作为当下大数据领域最炙手可热的数据处理框架，版本的更新、迭代速度也是非常之快，由学习的时候1.3的版本，到1.4，到1.6，到现在的2.0版本。以下为本人学习过程以及需要努力的方向：1、spark原理：rdd(新的2.0版本rdd并不是推荐的数据表示形式，而是DataFram)2、spark-streaming3、spark-sql4、spark-mllib">
<meta name="twitter:image" content="https://jamesxu9093.github.io/blog-img/1219-1.png">

<link rel="apple-touch-icon" href= "/apple-touch-icon.png">


    <link rel="alternate" href="/atom.xml" title="James的博客" type="application/atom+xml">



    <link rel="shortcut icon" href="/img/littleboy.png">



    <link href="//cdn.bootcss.com/animate.css/3.5.1/animate.min.css" rel="stylesheet">



    <link href="//cdn.bootcss.com/fancybox/2.1.5/jquery.fancybox.min.css" rel="stylesheet">



    <script src="//cdn.bootcss.com/pace/1.0.2/pace.min.js"></script>
    <link href="//cdn.bootcss.com/pace/1.0.2/themes/blue/pace-theme-minimal.css" rel="stylesheet">


<link rel="stylesheet" href="/css/style.css">



<link href="//cdn.bootcss.com/font-awesome/4.6.3/css/font-awesome.min.css" rel="stylesheet">


<title>Spark学习归纳总结 | James的博客</title>

<script src="//cdn.bootcss.com/jquery/2.2.4/jquery.min.js"></script>
<script src="//cdn.bootcss.com/clipboard.js/1.5.10/clipboard.min.js"></script>

<script>
    var yiliaConfig = {
        fancybox: true,
        animate: true,
        isHome: false,
        isPost: true,
        isArchive: false,
        isTag: false,
        isCategory: false,
        fancybox_js: "//cdn.bootcss.com/fancybox/2.1.5/jquery.fancybox.min.js",
        scrollreveal: "//cdn.bootcss.com/scrollReveal.js/3.1.4/scrollreveal.min.js",
        search: true
    }
</script>


    <script> yiliaConfig.jquery_ui = [false]; </script>



    <script> yiliaConfig.rootUrl = "\/";</script>






</head>
<body>
  <div id="container">
    <div class="left-col">
    <div class="overlay"></div>
<div class="intrude-less">
    <header id="header" class="inner">
        <a href="/" class="profilepic">
            <img src="/img/littleboy.png" class="animated zoomIn">
        </a>
        <hgroup>
          <h1 class="header-author"><a href="/">James</a></h1>
        </hgroup>

        

        
            <form id="search-form">
            <input type="text" id="local-search-input" name="q" placeholder="search..." class="search form-control" autocomplete="off" autocorrect="off" searchonload="false" />
            <i class="fa fa-times" onclick="resetSearch()"></i>
            </form>
            <div id="local-search-result"></div>
            <p class='no-result'>No results found <i class='fa fa-spinner fa-pulse'></i></p>
        


        
            <div id="switch-btn" class="switch-btn">
                <div class="icon">
                    <div class="icon-ctn">
                        <div class="icon-wrap icon-house" data-idx="0">
                            <div class="birdhouse"></div>
                            <div class="birdhouse_holes"></div>
                        </div>
                        <div class="icon-wrap icon-ribbon hide" data-idx="1">
                            <div class="ribbon"></div>
                        </div>
                        
                        <div class="icon-wrap icon-link hide" data-idx="2">
                            <div class="loopback_l"></div>
                            <div class="loopback_r"></div>
                        </div>
                        
                        
                        <div class="icon-wrap icon-me hide" data-idx="3">
                            <div class="user"></div>
                            <div class="shoulder"></div>
                        </div>
                        
                    </div>
                    
                </div>
                <div class="tips-box hide">
                    <div class="tips-arrow"></div>
                    <ul class="tips-inner">
                        <li>菜单</li>
                        <li>标签</li>
                        
                        <li>友情链接</li>
                        
                        
                        <li>关于我</li>
                        
                    </ul>
                </div>
            </div>
        

        <div id="switch-area" class="switch-area">
            <div class="switch-wrap">
                <section class="switch-part switch-part1">
                    <nav class="header-menu">
                        <ul>
                        
                            <li><a href="/">主页</a></li>
                        
                            <li><a href="/archives/">所有文章</a></li>
                        
                            <li><a href="/tags/">标签云</a></li>
                        
                            <li><a href="/about/">关于我</a></li>
                        
                        </ul>
                    </nav>
                    <nav class="header-nav">
                        <ul class="social">
                            
                                <a class="fa Email" href="mailto:735576698@qq.com" title="Email"></a>
                            
                                <a class="fa GitHub" href="https://github.com/" title="GitHub"></a>
                            
                                <a class="fa CSDN" href="http://my.csdn.net/my/mycsdn" title="CSDN"></a>
                            
                        </ul>
                    </nav>
                </section>
                
                
                <section class="switch-part switch-part2">
                    <div class="widget tagcloud" id="js-tagcloud">
                        <ul class="tag-list"><li class="tag-list-item"><a class="tag-list-link" href="/tags/algorithms/">algorithms</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/data-structures/">data-structures</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/markdown/">markdown</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/python/">python</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/skill/">skill</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/spark/">spark</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/study/">study</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/入门/">入门</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/学习/">学习</a></li></ul>
                    </div>
                </section>
                
                
                
                <section class="switch-part switch-part3">
                    <div id="js-friends">
                    
                      <a class="main-nav-link switch-friends-link" href="https://hexo.io">Hexo</a>
                    
                      <a class="main-nav-link switch-friends-link" href="https://pages.github.com/">GitHub</a>
                    
                      <a class="main-nav-link switch-friends-link" href="http://moxfive.xyz/">MOxFIVE</a>
                    
                    </div>
                </section>
                

                
                
                <section class="switch-part switch-part4">
                
                    <div id="js-aboutme">大数据，python</div>
                </section>
                
            </div>
        </div>
    </header>                
</div>
    </div>
    <div class="mid-col">
      <nav id="mobile-nav">
      <div class="overlay">
          <div class="slider-trigger"></div>
          <h1 class="header-author js-mobile-header hide"><a href="/" title="回到主页">James</a></h1>
      </div>
    <div class="intrude-less">
        <header id="header" class="inner">
            <a href="/" class="profilepic">
                <img src="/img/littleboy.png" class="animated zoomIn">
            </a>
            <hgroup>
              <h1 class="header-author"><a href="/" title="回到主页">James</a></h1>
            </hgroup>
            
            <nav class="header-menu">
                <ul>
                
                    <li><a href="/">主页</a></li>
                
                    <li><a href="/archives/">所有文章</a></li>
                
                    <li><a href="/tags/">标签云</a></li>
                
                    <li><a href="/about/">关于我</a></li>
                
                <div class="clearfix"></div>
                </ul>
            </nav>
            <nav class="header-nav">
                        <ul class="social">
                            
                                <a class="fa Email" target="_blank" href="mailto:735576698@qq.com" title="Email"></a>
                            
                                <a class="fa GitHub" target="_blank" href="https://github.com/" title="GitHub"></a>
                            
                                <a class="fa CSDN" target="_blank" href="http://my.csdn.net/my/mycsdn" title="CSDN"></a>
                            
                        </ul>
            </nav>
        </header>                
    </div>
    <link class="menu-list" tags="标签" friends="友情链接" about="关于我"/>
</nav>
      <div class="body-wrap"><article id="post-spark学习归纳" class="article article-type-post" itemscope itemprop="blogPost">
  
    <div class="article-meta">
      <a href="/2016/12/15/spark学习归纳/" class="article-date">
      <time datetime="2016-12-14T16:00:00.000Z" itemprop="datePublished">2016-12-15</time>
</a>


    </div>
  
  <div class="article-inner">
    
      <input type="hidden" class="isFancy" />
    
    
      <header class="article-header">
        
  
    <h1 class="article-title" itemprop="name">
      Spark学习归纳总结
    </h1>
  

      </header>
      
      <div class="article-info article-info-post">
        
    <div class="article-category tagcloud">
    <a class="article-category-link" href="/categories/spark/">spark</a>
    </div>


        
    <div class="article-tag tagcloud">
        <ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/spark/">spark</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/学习/">学习</a></li></ul>
    </div>

        <div class="clearfix"></div>
      </div>
      
    
    <div class="article-entry" itemprop="articleBody">
      
          
        <p>spark作为当下大数据领域最炙手可热的数据处理框架，版本的更新、迭代速度也是非常之快，由学习的时候1.3的版本，到1.4，到1.6，到现在的2.0版本。<br>以下为本人学习过程以及需要努力的方向：<br>1、spark原理：rdd(新的2.0版本rdd并不是推荐的数据表示形式，而是DataFram)<br>2、spark-streaming<br>3、spark-sql<br>4、spark-mllib<br><a id="more"></a></p>
<h2 id="资源归纳"><a href="#资源归纳" class="headerlink" title="资源归纳"></a>资源归纳</h2><p>1、快速入门<br><a href="http://spark.apache.org/docs/latest/quick-start.html" target="_blank" rel="external">http://spark.apache.org/docs/latest/quick-start.html</a><br>讲解map，reduce，flatmap，reducebykey等的用法<br>spark程序中可以应用任意的scala和java语言的特性(jar包，工具类，方法等，见例子)</p>
<p>2、官方手册<br><a href="http://spark.apache.org/docs/latest/programming-guide.html" target="_blank" rel="external">http://spark.apache.org/docs/latest/programming-guide.html</a></p>
<p>3、litaotao的归纳（spark科技日报）<br><a href="http://litaotao.github.io/introduction-to-spark?s=inner" target="_blank" rel="external">http://litaotao.github.io/introduction-to-spark?s=inner</a><br><a href="http://mp.weixin.qq.com/s?__biz=MzAwNzIzMDY5OA==&amp;mid=2651423985&amp;idx=1&amp;sn=962a12f58067618df12d20ab7a48868c&amp;scene=21#wechat_redirect" target="_blank" rel="external">http://mp.weixin.qq.com/s?__biz=MzAwNzIzMDY5OA==&amp;mid=2651423985&amp;idx=1&amp;sn=962a12f58067618df12d20ab7a48868c&amp;scene=21#wechat_redirect</a></p>
<h2 id="spark原理"><a href="#spark原理" class="headerlink" title="spark原理"></a>spark原理</h2><h3 id="基本介绍"><a href="#基本介绍" class="headerlink" title="基本介绍"></a>基本介绍</h3><p><strong>1.what’s spark？</strong><br>Apache Spark™ is a fast and general engine for large-scale data processing.</p>
<p><strong>2.Why is spark?</strong><br><em>Speed</em><br>Run programs up to 100x faster than Hadoop MapReduce in memory, or 10x faster on disk.<br>Apache Spark has an advanced DAG execution engine that supports cyclic data flow and in-memory computing.</p>
<p><em>Ease of Use</em><br>Write applications quickly in Java, Scala, Python, R.<br>Spark offers over 80 high-level operators that make it easy to build parallel apps. And you can use it interactively from the Scala, Python and R shells.</p>
<p><em>Generality</em><br>Combine SQL, streaming, and complex analytics.<br>Spark powers a stack of libraries including SQL and DataFrames, MLlib for machine learning, GraphX, and Spark Streaming. You can combine these libraries seamlessly in the same application.</p>
<p><em>Runs Everywhere</em><br>Spark runs on Hadoop, Mesos, standalone, or in the cloud. It can access diverse data sources including HDFS, Cassandra, HBase, and S3.<br>You can run Spark using its standalone cluster mode, on EC2, on Hadoop YARN, or on Apache Mesos. Access data in HDFS, Cassandra, HBase, Hive, Tachyon, and any Hadoop data source.</p>
<p><em>One stack rule them all !!!</em></p>
<p><strong>3. The Berkeley Data Analytics Stack</strong><br>实时流式计算：Stream Processing<br>批处理：Batch Process<br>点对点查询：Ad-hoc Queries</p>
<p><strong>4.与hadoop对比</strong><br>hadoop为什么慢：额外的复制，序列化，磁盘IO开销<br>spark为什么快：内存计算，DAG优化</p>
<p><strong>5.spark运行模式</strong><br>Local(多用于测试)<br>Standalone<br>Mesos<br>Yarn</p>
<h3 id="内核分析"><a href="#内核分析" class="headerlink" title="内核分析"></a>内核分析</h3><p><strong>1.spark介绍</strong><br>Spark是起源于美国加州大学伯克利分校AMPLab的大数据计算平台，在2010年开源，目前是Apache软件基金会的顶级项目。随着Spark在大数据计算领域的暂露头角，越来越多的企业开始关注和使用。2014年11月，Spark在Daytona Gray Sort 100TB Benchmark竞赛中打破了由Hadoop MapReduce保持的排序记录。Spark利用1/10的节点数，把100TB数据的排序时间从72分钟提高到了23分钟[1]。</p>
<p>Spark在架构上包括内核部分和4个官方子模块–Spark SQL、Spark Streaming、机器学习库MLlib和图计算库GraphX。图1所示为Spark在伯克利的数据分析软件栈BDAS [2]（<a href="https://amplab.cs.berkeley.edu/software/" target="_blank" rel="external">Berkeley Data Analytics Stack</a>）中的位置。可见Spark专注于数据的计算，而数据的存储在生产环境中往往还是由Hadoop分布式文件系统HDFS承担。</p>
<p><img src="/blog-img/1219-1.png" alt=""></p>
<p>Spark被设计成支持多场景的通用大数据计算平台，它可以解决大数据计算中的批处理，交互查询及流式计算等核心问题。Spark可以从多数据源的读取数据，并且拥有不断发展的机器学习库和图计算库供开发者使用。数据和计算在Spark内核及Spark的子模块中是打通的，这就意味着Spark内核和子模块之间成为一个整体。Spark的各个子模块以Spark内核为基础，进一步支持更多的计算场景，例如使用Spark SQL读入的数据可以作为机器学习库MLlib的输入。表1列举了一些在Spark平台上的计算场景。<br><img src="/blog-img/1219-2.png" alt=""><br>在本文写作是，Spark的最新版本为1.2.0，文中的示例代码也来自于这个版本。</p>
<p><strong>2. Spark内核介绍</strong></p>
<p>相信大数据工程师都非常了解Hadoop MapReduce一个最大的问题是在很多应用场景中速度非常慢，只适合离线的计算任务。这是由于MapReduce需要将任务划分成map和reduce两个阶段，map阶段产生的中间结果要写回磁盘，而在这两个阶段之间需要进行shuffle操作。Shuffle操作需要从网络中的各个节点进行数据拷贝，使其往往成为最为耗时的步骤，这也是Hadoop MapReduce慢的根本原因之一，大量的时间耗费在网络磁盘IO中而不是用于计算。在一些特定的计算场景中，例如像逻辑回归这样的迭代式的计算，MapReduce的弊端会显得更加明显。<br>那Spark是如果设计分布式计算的呢？首先我们需要理解Spark中最重要的概念–弹性分布数据集（Resilient Distributed Dataset），也就是RDD。</p>
<p><strong>2.1 弹性分布数据集RDD</strong></p>
<p>RDD是Spark中对数据和计算的抽象，是Spark中最核心的概念，它表示已被分片（partition），不可变的并能够被并行操作的数据集合。对RDD的操作分为两种transformation和action。Transformation操作是通过转换从一个或多个RDD生成新的RDD。Action操作是从RDD生成最后的计算结果。在Spark最新的版本中，提供丰富的transformation和action操作，比起MapReduce计算模型中仅有的两种操作，会大大简化程序开发的难度。</p>
<p>RDD的生成方式只有两种，一是从数据源读入，另一种就是从其它RDD通过transformation操作转换。一个典型的Spark程序就是通过Spark上下文环境（SparkContext）生成一个或多个RDD，在这些RDD上通过一系列的transformation操作生成最终的RDD，最后通过调用最终RDD的action方法输出结果。</p>
<p>每个RDD都可以用下面5个特性来表示，其中后两个为可选的：<br><em>&gt;&gt;&gt;&gt;&gt;分片列表（数据块列表）</em><br><em>&gt;&gt;&gt;&gt;&gt;计算每个分片的函数</em><br><em>&gt;&gt;&gt;&gt;&gt;对父RDD的依赖列表</em><br><em>&gt;&gt;&gt;&gt;&gt;对key-value类型的RDD的分片器（Partitioner）（可选）</em><br><em>&gt;&gt;&gt;&gt;&gt;每个数据分片的预定义地址列表（如HDFS上的数据块的地址）（可选）</em></p>
<p>虽然Spark是基于内存的计算，但RDD不光可以存储在内存中，根据useDisk、useMemory、useOffHeap, deserialized、replication五个参数的组合Spark提供了12种存储级别，在后面介绍RDD的容错机制时，我们会进一步理解。值得注意的是当StorageLevel设置成OFF_HEAP时，RDD实际被保存到Tachyon[5]中。Tachyon是一个基于内存的分布式文件系统，目前正在快速发展，本文不做详细介绍，可以通过其官方网站进一步了解。<br><figure class="highlight scala"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div></pre></td><td class="code"><pre><div class="line"><span class="class"><span class="keyword">class</span> <span class="title">StorageLevel</span> <span class="title">private</span>(<span class="params"></span></span></div><div class="line">    private var _useDisk: <span class="type">Boolean</span>,</div><div class="line">    private var _useMemory: <span class="type">Boolean</span>,</div><div class="line">    private var _useOffHeap: <span class="type">Boolean</span>,</div><div class="line">    private var _deserialized: <span class="type">Boolean</span>,</div><div class="line">    private var _replication: <span class="type">Int</span> = 1)</div><div class="line">  <span class="keyword">extends</span> <span class="type">Externalizable</span> &#123; <span class="comment">//…</span></div><div class="line">&#125;</div><div class="line">  <span class="keyword">val</span> <span class="type">NONE</span> = <span class="keyword">new</span> <span class="type">StorageLevel</span>(<span class="literal">false</span>, <span class="literal">false</span>, <span class="literal">false</span>, <span class="literal">false</span>)</div><div class="line">  <span class="keyword">val</span> <span class="type">DISK_ONLY</span> = <span class="keyword">new</span> <span class="type">StorageLevel</span>(<span class="literal">true</span>, <span class="literal">false</span>, <span class="literal">false</span>, <span class="literal">false</span>)</div><div class="line">  <span class="keyword">val</span> <span class="type">DISK_ONLY_2</span> = <span class="keyword">new</span> <span class="type">StorageLevel</span>(<span class="literal">true</span>, <span class="literal">false</span>, <span class="literal">false</span>, <span class="literal">false</span>, <span class="number">2</span>)</div><div class="line">  <span class="keyword">val</span> <span class="type">MEMORY_ONLY</span> = <span class="keyword">new</span> <span class="type">StorageLevel</span>(<span class="literal">false</span>, <span class="literal">true</span>, <span class="literal">false</span>, <span class="literal">true</span>)</div><div class="line">  <span class="keyword">val</span> <span class="type">MEMORY_ONLY_2</span> = <span class="keyword">new</span> <span class="type">StorageLevel</span>(<span class="literal">false</span>, <span class="literal">true</span>, <span class="literal">false</span>, <span class="literal">true</span>, <span class="number">2</span>)</div><div class="line">  <span class="keyword">val</span> <span class="type">MEMORY_ONLY_SER</span> = <span class="keyword">new</span> <span class="type">StorageLevel</span>(<span class="literal">false</span>, <span class="literal">true</span>, <span class="literal">false</span>, <span class="literal">false</span>)</div><div class="line">  <span class="keyword">val</span> <span class="type">MEMORY_ONLY_SER_2</span> = <span class="keyword">new</span> <span class="type">StorageLevel</span>(<span class="literal">false</span>, <span class="literal">true</span>, <span class="literal">false</span>, <span class="literal">false</span>, <span class="number">2</span>)</div><div class="line">  <span class="keyword">val</span> <span class="type">MEMORY_AND_DISK</span> = <span class="keyword">new</span> <span class="type">StorageLevel</span>(<span class="literal">true</span>, <span class="literal">true</span>, <span class="literal">false</span>, <span class="literal">true</span>)</div><div class="line">  <span class="keyword">val</span> <span class="type">MEMORY_AND_DISK_2</span> = <span class="keyword">new</span> <span class="type">StorageLevel</span>(<span class="literal">true</span>, <span class="literal">true</span>, <span class="literal">false</span>, <span class="literal">true</span>, <span class="number">2</span>)</div><div class="line">  <span class="keyword">val</span> <span class="type">MEMORY_AND_DISK_SER</span> = <span class="keyword">new</span> <span class="type">StorageLevel</span>(<span class="literal">true</span>, <span class="literal">true</span>, <span class="literal">false</span>, <span class="literal">false</span>)</div><div class="line">  <span class="keyword">val</span> <span class="type">MEMORY_AND_DISK_SER_2</span> = <span class="keyword">new</span> <span class="type">StorageLevel</span>(<span class="literal">true</span>, <span class="literal">true</span>, <span class="literal">false</span>, <span class="literal">false</span>, <span class="number">2</span>)</div><div class="line">  <span class="keyword">val</span> <span class="type">OFF_HEAP</span> = <span class="keyword">new</span> <span class="type">StorageLevel</span>(<span class="literal">false</span>, <span class="literal">false</span>, <span class="literal">true</span>, <span class="literal">false</span>)</div></pre></td></tr></table></figure></p>
<p><strong>2.2 DAG、Stage与任务的生成</strong></p>
<p>Spark的计算发生在RDD的action操作，而对action之前的所有transformation，Spark只是记录下RDD生成的轨迹，而不会触发真正的计算。</p>
<p>Spark内核会在需要计算发生的时刻绘制一张关于计算路径的有向无环图，也就是DAG。举个例子，在图2中，从输入中逻辑上生成A和C两个RDD，经过一系列transformation操作，逻辑上生成了F，注意，我们说的是逻辑上，因为这时候计算没有发生，Spark内核做的事情只是记录了RDD的生成和依赖关系。当F要进行输出时，也就是F进行了action操作，Spark会根据RDD的依赖生成DAG，并从起点开始真正的计算。<br><img src="/blog-img/1219-3.png" alt=""><br>有了计算的DAG图，Spark内核下一步的任务就是根据DAG图将计算划分成任务集，也就是Stage，这样可以将任务提交到计算节点进行真正的计算。Spark计算的中间结果默认是保存在内存中的，Spark在划分Stage的时候会充分考虑在分布式计算中可流水线计算（pipeline）的部分来提高计算的效率，而在这个过程中，主要的根据就是RDD的依赖类型。根据不同的transformation操作，RDD的依赖可以分为窄依赖（Narrow Dependency）和宽依赖（Wide Dependency，在代码中为ShuffleDependency）两种类型。窄依赖指的是生成的RDD中每个partition只依赖于父RDD(s) 固定的partition。宽依赖指的是生成的RDD的每一个partition都依赖于父 RDD(s) 所有partition。窄依赖典型的操作有map, filter, union等，宽依赖典型的操作有groupByKey, sortByKey等。可以看到，宽依赖往往意味着shuffle操作，这也是Spark划分stage的主要边界。对于窄依赖，Spark会将其尽量划分在同一个stage中，因为它们可以进行流水线计算。<br><img src="/blog-img/1219-4.png" alt=""><br>我们再通过图4详细解释一下Spark中的Stage划分。我们从HDFS中读入数据生成3个不同的RDD，通过一系列transformation操作后再将计算结果保存回HDFS。可以看到这幅DAG中只有join操作是一个宽依赖，Spark内核会以此为边界将其前后划分成不同的Stage. 同时我们可以注意到，在图中Stage2中，从map到union都是窄依赖，这两步操作可以形成一个流水线操作，通过map操作生成的partition可以不用等待整个RDD计算结束，而是继续进行union操作，这样大大提高了计算的效率。<br><img src="/blog-img/1219-5.png" alt=""><br>Spark在运行时会把Stage包装成任务提交，有父Stage的Spark会先提交父Stage。弄清楚了Spark划分计算的原理，我们再结合源码看一看这其中的过程。下面的代码是DAGScheduler中的得到一个RDD父Stage的函数，可以看到宽依赖为划分Stage的边界。</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div></pre></td><td class="code"><pre><div class="line"><span class="comment">/**</span></div><div class="line">   * Get or create the list of parent stages for a given RDD. The stages will be assigned the</div><div class="line">   * provided jobId if they haven't already been created with a lower jobId.</div><div class="line">   */</div><div class="line">  <span class="keyword">private</span> <span class="function"><span class="keyword">def</span> <span class="title">getParentStages</span></span>(rdd: <span class="type">RDD</span>[_], jobId: <span class="type">Int</span>): <span class="type">List</span>[<span class="type">Stage</span>] = &#123;</div><div class="line">    <span class="keyword">val</span> parents = <span class="keyword">new</span> <span class="type">HashSet</span>[<span class="type">Stage</span>]</div><div class="line">    <span class="keyword">val</span> visited = <span class="keyword">new</span> <span class="type">HashSet</span>[<span class="type">RDD</span>[_]]</div><div class="line">    <span class="comment">// We are manually maintaining a stack here to prevent StackOverflowError</span></div><div class="line">    <span class="comment">// caused by recursively visiting</span></div><div class="line">    <span class="keyword">val</span> waitingForVisit = <span class="keyword">new</span> <span class="type">Stack</span>[<span class="type">RDD</span>[_]]</div><div class="line">    <span class="function"><span class="keyword">def</span> <span class="title">visit</span></span>(r: <span class="type">RDD</span>[_]) &#123;</div><div class="line">      <span class="keyword">if</span> (!visited(r)) &#123;</div><div class="line">        visited += r</div><div class="line">        <span class="comment">// Kind of ugly: need to register RDDs with the cache here since</span></div><div class="line">        <span class="comment">// we can't do it in its constructor because # of partitions is unknown</span></div><div class="line">        <span class="keyword">for</span> (dep &lt;- r.dependencies) &#123;</div><div class="line">          dep <span class="keyword">match</span> &#123;</div><div class="line">            <span class="keyword">case</span> shufDep: <span class="type">ShuffleDependency</span>[_, _, _] =&gt;</div><div class="line">              parents += getShuffleMapStage(shufDep, jobId)</div><div class="line">            <span class="keyword">case</span> _ =&gt;</div><div class="line">              waitingForVisit.push(dep.rdd)</div><div class="line">          &#125;</div><div class="line">        &#125;</div><div class="line">      &#125;</div><div class="line">    &#125;</div><div class="line">    waitingForVisit.push(rdd)</div><div class="line">    <span class="keyword">while</span> (!waitingForVisit.isEmpty) &#123;</div><div class="line">      visit(waitingForVisit.pop())</div><div class="line">    &#125;</div><div class="line">    parents.toList</div><div class="line">  &#125;</div></pre></td></tr></table></figure>
<p>上面提到Spark的计算是从RDD调用action操作时候触发的，我们来看一个action的代码:<br>RDD的collect方法是一个action操作，作用是将RDD中的数据返回到一个数组中。可以看到，在此action中，会触发Spark上下文环境SparkContext中的runJob方法，这是一系列计算的起点。<br><figure class="highlight scala"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">abstract</span> <span class="class"><span class="keyword">class</span> <span class="title">RDD</span>[<span class="type">T</span>: <span class="type">ClassTag</span>](<span class="params"></span></span></div><div class="line">    @transient private var sc: <span class="type">SparkContext</span>,</div><div class="line">    @transient private var deps: <span class="type">Seq</span>[<span class="type">Dependency</span>[_]]</div><div class="line">  ) <span class="keyword">extends</span> <span class="title">Serializable</span> <span class="keyword">with</span> <span class="title">Logging</span> &#123;</div><div class="line">  <span class="comment">//…</span></div><div class="line"><span class="comment">/**</span></div><div class="line">   * Return an array that contains all of the elements in this RDD.</div><div class="line">   */</div><div class="line">  <span class="function"><span class="keyword">def</span> <span class="title">collect</span></span>(): <span class="type">Array</span>[<span class="type">T</span>] = &#123;</div><div class="line">    <span class="keyword">val</span> results = sc.runJob(<span class="keyword">this</span>, (iter: <span class="type">Iterator</span>[<span class="type">T</span>]) =&gt; iter.toArray)</div><div class="line">    <span class="type">Array</span>.concat(results: _*)</div><div class="line">  &#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure></p>
<p>SparkContext拥有DAGScheduler的实例，在runJob方法中会进一步调用DAGScheduler的runJob方法。在此时，DAGScheduler会生成DAG和Stage，将Stage提交给TaskScheduler。TaskSchduler将Stage包装成TaskSet，发送到Worker节点进行真正的计算，同时还要监测任务状态，重试失败和长时间无返回的任务。整个过程如图5所示。<br><img src="/blog-img/1219-6.png" alt=""></p>
<p><strong>2.3 RDD的缓存与容错</strong></p>
<p>上文提到，Spark的计算是从action开始触发的，如果在action操作之前逻辑上很多transformation操作，一旦中间发生计算失败，Spark会重新提交任务，这在很多场景中代价过大。还有一些场景，如有些迭代算法，计算的中间结果会被重复使用，重复计算同样增加计算时间和造成资源浪费。因此，在提高计算效率和更好支持容错，Spark提供了基于RDD的cache机制和checkpoint机制。</p>
<p>我们可以通过RDD的toDebugString来查看其递归的依赖信息，图6展示了在spark shell中通过调用这个函数来查看wordCount RDD的依赖关系，也就是它的Lineage.<br><img src="/blog-img/1219-7.png" alt=""><br>如果发现Lineage过长或者里面有被多次重复使用的RDD，我们就可以考虑使用cache机制或checkpoint机制了。</p>
<p>我们可以通过在程序中直接调用RDD的cache方法将其保存在内存中，这样这个RDD就可以被多个任务共享，避免重复计算。另外，RDD还提供了更为灵活的persist方法，可以指定存储级别。从源码中可以看到RDD.cache就是简单的调用了RDD.persist(StorageLevel.MEMORY_ONLY)。</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line"><span class="comment">/** Persist this RDD with the default storage level (`MEMORY_ONLY`). */</span></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">persist</span></span>(): <span class="keyword">this</span>.<span class="keyword">type</span> = persist(<span class="type">StorageLevel</span>.<span class="type">MEMORY_ONLY</span>)</div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">cache</span></span>(): <span class="keyword">this</span>.<span class="keyword">type</span> = persist()</div></pre></td></tr></table></figure>
<p>同样，我们可以调用RDD的checkpoint方法将其保存到磁盘。我们需要在SparkContext中设置checkpoint的目录，否则调用会抛出异常。值得注意的是，在调用checkpoint之前建议先调用cache方法将RDD放入内存，否则将RDD保存到文件的时候需要重新计算。</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div></pre></td><td class="code"><pre><div class="line"><span class="comment">/**</span></div><div class="line">   * Mark this RDD for checkpointing. It will be saved to a file inside the checkpoint</div><div class="line">   * directory set with SparkContext.setCheckpointDir() and all references to its parent</div><div class="line">   * RDDs will be removed. This function must be called before any job has been</div><div class="line">   * executed on this RDD. It is strongly recommended that this RDD is persisted in</div><div class="line">   * memory, otherwise saving it on a file will require recomputation.</div><div class="line">   */</div><div class="line">  <span class="function"><span class="keyword">def</span> <span class="title">checkpoint</span></span>() &#123;</div><div class="line">    <span class="keyword">if</span> (context.checkpointDir.isEmpty) &#123;</div><div class="line">      <span class="keyword">throw</span> <span class="keyword">new</span> <span class="type">SparkException</span>(<span class="string">"Checkpoint directory has not been set in the SparkContext"</span>)</div><div class="line">    &#125; <span class="keyword">else</span> <span class="keyword">if</span> (checkpointData.isEmpty) &#123;</div><div class="line">      checkpointData = <span class="type">Some</span>(<span class="keyword">new</span> <span class="type">RDDCheckpointData</span>(<span class="keyword">this</span>))</div><div class="line">      checkpointData.get.markForCheckpoint()</div><div class="line">    &#125;</div><div class="line">  &#125;</div></pre></td></tr></table></figure>
<p>Cache机制和checkpoint机制的差别在于cache将RDD保存到内存，并保留Lineage，如果缓存失效RDD还可以通过Lineage重建。而checkpoint将RDD落地到磁盘并切断Lineage，由文件系统保证其重建。</p>
<p><strong>2.4 Spark任务的部署</strong></p>
<p>Spark的集群部署分为Standalone、Mesos和Yarn三种模式，我们以Standalone模式为例，简单介绍Spark程序的部署。如图7示，集群中的Spark程序运行时分为3种角色，driver, master和worker（slave）。在集群启动前，首先要配置master和worker节点。启动集群后，worker节点会向master节点注册自己，master节点会维护worker节点的心跳。Spark程序都需要先创建Spark上下文环境，也就是SparkContext。创建SparkContext的进程就成为了driver角色，上一节提到的DAGScheduler和TaskScheduler都在driver中运行。Spark程序在提交时要指定master的地址，这样可以在程序启动时向master申请worker的计算资源。Driver，master和worker之间的通信由Akka[4]支持。Akka 也使用 Scala 编写，用于构建可容错的、高可伸缩性的Actor 模型应用。关于Akka，可以访问其官方网站进行进一步了解，本文不做详细介绍。</p>
<p><img src="/blog-img/1219-8.png" alt=""></p>
<p><strong>3. 更深一步了解Spark内核</strong></p>
<p>了解了Spark内核的基本概念和实现后，更深一步理解其工作原理的最好方法就是阅读源码。最新的Spark源码可以从Spark官方[3]网站下载。源码推荐使用IntelliJ IDEA阅读，会自动安装Scala插件。读者可以从core工程，也就是Spark内核工程开始阅读，更可以设置断点尝试跟踪一个任务的执行。另外，读者还可以通过分析Spark的日志来进一步理解Spark的运行机制，Spark使用log4j记录日志，可以在启动集群前修改log4j的配置文件来配置日志输出和格式。</p>
<p><strong>参考资料</strong><br>[1] <a href="http://spark.apache.org/news/spark-wins-daytona-gray-sort-100tb-benchmark.html" target="_blank" rel="external">http://spark.apache.org/news/spark-wins-daytona-gray-sort-100tb-benchmark.html</a><br>[2] <a href="https://amplab.cs.berkeley.edu/software/" target="_blank" rel="external">https://amplab.cs.berkeley.edu/software/</a><br>[3] <a href="http://spark.apache.org/downloads.html" target="_blank" rel="external">http://spark.apache.org/downloads.html</a><br>[4] <a href="http://akka.io/docs/" target="_blank" rel="external">http://akka.io/docs/</a><br>[5] <a href="http://www.tachyonproject.org/" target="_blank" rel="external">http://www.tachyonproject.org/</a></p>
<p>本文来自： <a href="http://www.chinahadoop.cn/group/3/thread/956" target="_blank" rel="external">http://www.chinahadoop.cn/group/3/thread/956</a> 对原文有少许修改</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div></pre></td><td class="code"><pre><div class="line"><span class="comment">/**</span></div><div class="line">   * Mark this RDD for checkpointing. It will be saved to a file inside the checkpoint</div><div class="line">   * directory set with SparkContext.setCheckpointDir() and all references to its parent</div><div class="line">   * RDDs will be removed. This function must be called before any job has been</div><div class="line">   * executed on this RDD. It is strongly recommended that this RDD is persisted in</div><div class="line">   * memory, otherwise saving it on a file will require recomputation.</div><div class="line">   */</div><div class="line">  <span class="function"><span class="keyword">def</span> <span class="title">checkpoint</span></span>() &#123;</div><div class="line">    <span class="keyword">if</span> (context.checkpointDir.isEmpty) &#123;</div><div class="line">      <span class="keyword">throw</span> <span class="keyword">new</span> <span class="type">SparkException</span>(<span class="string">"Checkpoint directory has not been set in the SparkContext"</span>)</div><div class="line">    &#125; <span class="keyword">else</span> <span class="keyword">if</span> (checkpointData.isEmpty) &#123;</div><div class="line">      checkpointData = <span class="type">Some</span>(<span class="keyword">new</span> <span class="type">RDDCheckpointData</span>(<span class="keyword">this</span>))</div><div class="line">      checkpointData.get.markForCheckpoint()</div><div class="line">    &#125;</div><div class="line">  &#125;</div></pre></td></tr></table></figure>
<h2 id="spark集群搭建"><a href="#spark集群搭建" class="headerlink" title="spark集群搭建"></a>spark集群搭建</h2><p>生产搭建</p>
<h2 id="spark-ui监控"><a href="#spark-ui监控" class="headerlink" title="spark-ui监控"></a>spark-ui监控</h2><h2 id="spark-streaming"><a href="#spark-streaming" class="headerlink" title="spark-streaming"></a>spark-streaming</h2>
      
    </div>
    
  </div>
  
    
    <div class="copyright">
        <p><span>本文标题:</span><a href="/2016/12/15/spark学习归纳/">Spark学习归纳总结</a></p>
        <p><span>文章作者:</span><a href="/" title="回到主页">James</a></p>
        <p><span>发布时间:</span>2016-12-15, 00:00:00</p>
        <p><span>最后更新:</span>2016-12-19, 15:14:06</p>
        <p>
            <span>原始链接:</span><a class="post-url" href="/2016/12/15/spark学习归纳/" title="Spark学习归纳总结">https://jamesxu9093.github.io/2016/12/15/spark学习归纳/</a>
            <span class="copy-path" data-clipboard-text="原文: https://jamesxu9093.github.io/2016/12/15/spark学习归纳/　　作者: James" title="点击复制文章链接"><i class="fa fa-clipboard"></i></span>
            <script> var clipboard = new Clipboard('.copy-path'); </script>
        </p>
        <p>
            <span>许可协议:</span><i class="fa fa-creative-commons"></i> <a rel="license" href="http://creativecommons.org/licenses/by-nc-sa/4.0/" title="CC BY-NC-SA 4.0 International" target = "_blank">"署名-非商用-相同方式共享 4.0"</a> 转载请保留原文链接及作者。
        </p>
    </div>



    <nav id="article-nav">
        
        
            <div id="article-nav-older" class="article-nav-title">
                <a href="/2016/12/14/Python入门到精通之路/">
                    Python入门到精通
                </a>
            </div>
        
    </nav>

  
</article>

    <div id="toc" class="toc-article">
        <strong class="toc-title">文章目录</strong>
        
            <ol class="toc"><li class="toc-item toc-level-2"><a class="toc-link" href="#资源归纳"><span class="toc-number">1.</span> <span class="toc-text">资源归纳</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#spark原理"><span class="toc-number">2.</span> <span class="toc-text">spark原理</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#基本介绍"><span class="toc-number">2.1.</span> <span class="toc-text">基本介绍</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#内核分析"><span class="toc-number">2.2.</span> <span class="toc-text">内核分析</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#spark集群搭建"><span class="toc-number">3.</span> <span class="toc-text">spark集群搭建</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#spark-ui监控"><span class="toc-number">4.</span> <span class="toc-text">spark-ui监控</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#spark-streaming"><span class="toc-number">5.</span> <span class="toc-text">spark-streaming</span></a></li></ol>
        
    </div>
    <style>
        .left-col .switch-btn,
        .left-col .switch-area {
            display: none;
        }
        .toc-level-3 i,
        .toc-level-3 ol {
            display: none !important;
        }
    </style>

    <input type="button" id="tocButton" value="隐藏目录"  title="点击按钮隐藏或者显示文章目录">

    <script>
        yiliaConfig.toc = ["隐藏目录", "显示目录", !!"false"];
    </script>



    
<div class="share">
    
        <div class="bdsharebuttonbox">
            <a href="#" class="fa fa-twitter bds_twi" data-cmd="twi" title="分享到推特"></a>
            <a href="#" class="fa fa-weibo bds_tsina" data-cmd="tsina" title="分享到新浪微博"></a>
            <a href="#" class="fa fa-qq bds_sqq" data-cmd="sqq" title="分享给 QQ 好友"></a>
            <a href="#" class="fa fa-files-o bds_copy" data-cmd="copy" title="复制网址"></a>
            <a href="#" class="fa fa fa-envelope-o bds_mail" data-cmd="mail" title="通过邮件分享"></a>
            <a href="#" class="fa fa-weixin bds_weixin" data-cmd="weixin" title="生成文章二维码"></a>
            <a href="#" class="fa fa-share-alt bds_more" data-cmd="more"></i></a>
        </div>
        <script>
            window._bd_share_config={
                "common":{"bdSnsKey":{},"bdText":"Spark学习归纳总结　| James的博客　","bdMini":"2","bdMiniList":false,"bdPic":"","bdStyle":"0","bdSize":"24"},"share":{}};with(document)0[(getElementsByTagName('head')[0]||body).appendChild(createElement('script')).src='http://bdimg.share.baidu.com/static/api/js/share.js?v=89860593.js?cdnversion='+~(-new Date()/36e5)];
        </script>
    

    
</div>







    
      <div class="duoshuo" id="comments">
    <div id="comment-box" ></div>
    <div class="ds-thread" id="ds-thread" data-thread-key="2016/12/15/spark学习归纳/" data-title="Spark学习归纳总结" data-url="https://jamesxu9093.github.io/2016/12/15/spark学习归纳/"></div>
    <script>
        var duoshuoQuery = {short_name:"jamesxu9093"};
        var loadComment = function(){
            var d = document, s = d.createElement('script');
            s.src = (document.location.protocol == 'https:' ? 'https:' : 'http:') + '//static.duoshuo.com/embed.js';
            s.async = true; s.charset = 'UTF-8';
            (d.head || d.body).appendChild(s);
        }

        
    </script>
    
    <script> loadComment(); </script>

</div>
    




    <div class="scroll" id="post-nav-button">
        
            <a href="/" title="回到主页"><i class="fa fa-home"></i></a>
        

        <a title="文章列表"><i class="fa fa-bars"></i><i class="fa fa-times"></i></a>

        
            <a href="/2016/12/14/Python入门到精通之路/" title="下一篇: Python入门到精通">
                <i class="fa fa-angle-right"></i>
            </a>
        
    </div>

    <ul class="post-list"><li class="post-list-item"><a class="post-list-link" href="/2016/12/15/spark学习归纳/">Spark学习归纳总结</a></li><li class="post-list-item"><a class="post-list-link" href="/2016/12/14/Python入门到精通之路/">Python入门到精通</a></li><li class="post-list-item"><a class="post-list-link" href="/2016/12/09/DataStructuresAndAlgorithmsInPython/">DataStructuresAndAlgorithmsInPython读书笔记</a></li><li class="post-list-item"><a class="post-list-link" href="/2016/12/08/markdown/">hexo + github page构建一个自用简易博客平台，使用markdown语法写作</a></li></ul>




    <script>
        
    </script>
</div>
      <footer id="footer">
    <div class="outer">
        <div id="footer-info">
            <div class="footer-left">
                <i class="fa fa-copyright"></i> 
                2016 James
            </div>
            <div class="footer-right">
                <a href="http://hexo.io/" target="_blank" title="快速、简洁且高效的博客框架">Hexo</a>  Theme <a href="https://github.com/MOxFIVE/hexo-theme-yelee" target="_blank" title="简而不减 Hexo 双栏博客主题  v3.5">Yelee</a> by MOxFIVE <i class="fa fa-heart animated infinite pulse"></i>
            </div>
        </div>
        
            <div class="visit">
                
                    <span id="busuanzi_container_site_pv" style='display:none'>
                        <span id="site-visit" title="本站到访数"><i class="fa fa-user" aria-hidden="true"></i><span id="busuanzi_value_site_uv"></span>
                        </span>
                    </span>
                
                
                    <span>| </span>
                
                
                    <span id="busuanzi_container_page_pv" style='display:none'>
                        <span id="page-visit"  title="本页阅读量"><i class="fa fa-eye animated infinite pulse" aria-hidden="true"></i><span id="busuanzi_value_page_pv"></span>
                        </span>
                    </span>
                
            </div>
        
    </div>
</footer>
    </div>
    
<script data-main="/js/main.js" src="//cdn.bootcss.com/require.js/2.2.0/require.min.js"></script>





    <script type="text/x-mathjax-config">
MathJax.Hub.Config({
    tex2jax: {
        inlineMath: [ ['$','$'], ["\\(","\\)"]  ],
        processEscapes: true,
        skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
    }
});

MathJax.Hub.Queue(function() {
    var all = MathJax.Hub.getAllJax(), i;
    for(i=0; i < all.length; i += 1) {
        all[i].SourceElement().parentNode.className += ' has-jax';                 
    }       
});
</script>

<script src="//cdn.bootcss.com/mathjax/2.6.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
</script>


<div class="scroll" id="scroll">
    <a href="#" title="返回顶部"><i class="fa fa-arrow-up"></i></a>
    <a href="#comments" onclick="load$hide();" title="查看评论"><i class="fa fa-comments-o"></i></a>
    <a href="#footer" title="转到底部"><i class="fa fa-arrow-down"></i></a>
</div>
<script>
    // Open in New Window
    
        var oOpenInNew = {
            
            
            
            
            
            
             archives: ".archive-article-title", 
             miniArchives: "a.post-list-link", 
            
             friends: "#js-friends a", 
             socail: ".social a" 
        }
        for (var x in oOpenInNew) {
            $(oOpenInNew[x]).attr("target", "_blank");
        }
    
</script>

<script async src="https://dn-lbstatics.qbox.me/busuanzi/2.3/busuanzi.pure.mini.js">
</script>
  </div>
</body>
</html>